{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb46c594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shaba\\OneDrive\\Desktop\\RAG Chatbot\\.venv-1\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader  #  Reads PDF files page by page.\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings  #Converts text into embeddings (numerical vectors).\n",
    "from langchain.text_splitter import CharacterTextSplitter  # Splits long text into smaller chunks (so embeddings don’t cut mid-sentence)\n",
    "from langchain.vectorstores import FAISS   # Facebook’s Vector DB library → stores embeddings for fast similarity search.\n",
    "import google.generativeai as genai  #  Google Gemini SDK (Generative AI API)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b12e1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaba\\AppData\\Local\\Temp\\ipykernel_18568\\3337247560.py:8: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "gemini_key = os.environ.get(\"GEMINI_KEY\")\n",
    "\n",
    "genai.configure(api_key=gemini_key)\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5b9d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO READ PDF AND SPLIT INTO PARAGRAPHS\n",
    "\n",
    "def split_paragraphs(rawText):\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\",\n",
    "        chunk_size=200,\n",
    "        chunk_overlap=20,\n",
    "        length_function=len,\n",
    "    )\n",
    "    return text_splitter.split_text(rawText)\n",
    "\n",
    "\"\"\"\n",
    "Breaks text into chunks of 200 characters with an overlap of 20.\n",
    "Overlap prevents context loss between chunks.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_pdfs(pdfs):\n",
    "    text_chunks = []\n",
    "    \"\"\"\n",
    "    Loops over each PDF → extracts text page by page.\n",
    "    Splits into chunks.\n",
    "    Collects all chunks into a list.\n",
    "    Prints first 5 for verification.\n",
    "    \"\"\"\n",
    "\n",
    "    for pdf in pdfs:\n",
    "        reader = PdfReader(pdf)\n",
    "        for page in reader.pages:\n",
    "            raw = page.extract_text()\n",
    "            chunks = split_paragraphs(raw)\n",
    "            text_chunks += chunks\n",
    "    print(\"HERE WE HAVE AN EXAMPLE OF WHAT WE HAVE IN CHUNKS\")\n",
    "    print(text_chunks[:5])  # Display first 5 chunks for verification\n",
    "    return text_chunks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4190959d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HERE WE HAVE AN EXAMPLE OF WHAT WE HAVE IN CHUNKS\n",
      "['Notes By – Prof. S.A. Langote  \\nUnit No.1: Introduction to Computer Networks  \\n \\n➢ Uses of Computer Networks  \\no Business Applications  \\nMost companies have a substantial number of computers. For', 'example, a company may have a computer for each worker and use them \\nto design products, write brochures, and do the payroll. Initially, some of', 'these computers may have worked in isolation from the others, but at some \\npoint, management may have decided to connect them to be able to \\ndistribute information throughout the company.', 'Put in slightly more general form, the issue here is resource sharing. \\nThe goal is to make all programs, equipment, and especially data available', 'to anyone on the network without regard to the physical location of the \\nresource or the user. An obvious and wides pread example is having a group']\n"
     ]
    }
   ],
   "source": [
    "list_of_pdfs = [\"Chapter 1.pdf\"]\n",
    "text_chunks = load_pdfs(list_of_pdfs)\n",
    "\n",
    "\"\"\"\n",
    "Reads Chapter 1.pdf.\n",
    "Converts it into small text_chunks.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62685a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = FAISS.from_texts(text_chunks, embeddings)  #   Takes your text chunks → converts into embeddings → stores them in FAISS DB.\n",
    "store.save_local(\"./myvectorstore\") #  Saves the vector DB to ./myvectorstore for reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3974ff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI   # Wrapper for Gemini chat models (like gemini-1.5-flash).\n",
    "from langchain.chains import RetrievalQA  #   LangChain chain that connects retriever + LLM → full RAG pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b6242d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'Explain Computer Network Reference model.', 'result': 'Based on the provided text, there is mention of the ISO OSI (Open Systems Interconnection) Reference Model.  The text states that it deals with connecting open systems, and that it was revised in 1995. However, no further details about the model itself are given.'}\n"
     ]
    }
   ],
   "source": [
    "store = FAISS.load_local(\"myvectorstore\", embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0, google_api_key=gemini_key)\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(llm=llm, retriever=store.as_retriever())\n",
    "result = chain({\"query\": \"Explain Computer Network Reference model.\"})\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-1 (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
