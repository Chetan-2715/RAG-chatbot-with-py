{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e40cd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80a999d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your prompt template\n",
    "prompt = \"\"\"You are a assistant for question answering tasks.\n",
    "use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Answer in bullet points.make sure to use the context provided.\n",
    "Question : {question}\n",
    "Context:{context}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab49e376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user said \"Hi\". I need to respond politely. Let me think about the best way to reply.\\n\\nFirst, acknowledge their greeting. Maybe say \"Hello!\" to keep it friendly. Then offer assistance. They might be testing if I\\'m responsive or just starting a conversation. I should keep it open-ended so they feel comfortable sharing more.\\n\\nI should avoid any markdown and keep the response simple. No need for extra explanations unless they ask. Just a straightforward greeting and offer to help. Make sure the tone is warm and approachable. Alright, that should cover it.\\n</think>\\n\\nHello! How can I assist you today? ðŸ˜Š', additional_kwargs={}, response_metadata={'model': 'qwen3:1.7b', 'created_at': '2025-08-24T03:34:32.4202507Z', 'done': True, 'done_reason': 'stop', 'total_duration': 8088521500, 'load_duration': 4816792800, 'prompt_eval_count': 9, 'prompt_eval_duration': 490568800, 'eval_count': 133, 'eval_duration': 2772004100, 'model_name': 'qwen3:1.7b'}, id='run--a566c2bc-d5df-4423-9429-ce901f521187-0', usage_metadata={'input_tokens': 9, 'output_tokens': 133, 'total_tokens': 142})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOllama(model=\"qwen3:1.7b\",base_url=\"http://localhost:11434\")\n",
    "llm.invoke(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08b7de22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example mock retriever for demonstration purposes\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "class MockDoc:\n",
    "    def __init__(self, page_content):\n",
    "        self.page_content = page_content\n",
    "\n",
    "def mock_retriever(input):\n",
    "    # Returns a list of mock documents\n",
    "    return [MockDoc(\"This is a sample context document.\")]\n",
    "\n",
    "retriever = RunnableLambda(mock_retriever)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "format_docs_runnable = RunnableLambda(format_docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs_runnable, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3d438c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-1 (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
